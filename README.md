# Autoencoders

PyTorch implementation of various autoencoder architectures using the MNIST dataset. <br/>
*Results are in the jupyter notebooks*

### Architectures implemented :
1. Vanilla autoencoder ([using FCN](https://github.com/jayeshk7/Autoencoders/blob/master/Simple%20Autoencoder.ipynb))
2. Denoising autoencoder ([using FCN](https://github.com/jayeshk7/Autoencoders/blob/master/Denoising%20AE.ipynb))([using convolutions](https://github.com/jayeshk7/Autoencoders/blob/master/Denoise%20using%20conv.py))

### TO-DO :
- [ ] Sparse autoencoder 
- [ ] Variational autoencoder
- [ ] Beta-VAE

### Resources
1. [From Autoencoder to beta-VAE](https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html) (including research papers cited in the blog)