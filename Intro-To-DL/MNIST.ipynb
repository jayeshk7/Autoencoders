{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('mnist_train.csv',header = None)\n",
    "data = np.array(df)\n",
    "x = (data[:,1:].transpose())/255\n",
    "m = x.shape[1]\n",
    "n = x.shape[0]\n",
    "y_orig = data[:,0:1].transpose()\n",
    "y = np.zeros((10,m))    #one hot encoding vimportant\n",
    "for i in range(m): \n",
    "    y[int(y_orig[0,i]),i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    reluu = np.maximum(x,0)\n",
    "    return reluu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backrelu(x):\n",
    "    result = (x + np.abs(x))/(2*np.abs(x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    expp = np.exp(x)\n",
    "    some = np.sum(expp, axis=0, keepdims=True)\n",
    "    result = expp/some\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_parameters(): \n",
    "    for z in range(1,len(layers)):\n",
    "        w = np.random.randn(layers[z],layers[z-1])*0.01\n",
    "        b = np.zeros((layers[z],1))\n",
    "        w_cache[\"w\" + str(z)] = w\n",
    "        b_cache[\"b\" + str(z)] = b\n",
    "    \n",
    "    parameters = {\"w_cache\" : w_cache,\n",
    "                  \"b_cache\" : b_cache}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(parameters,x):\n",
    "    \n",
    "    a_cache['a0'] = x\n",
    "    activation = x\n",
    "    \n",
    "    for l in range(1,len(layers)-1):\n",
    "        w = parameters[\"w_cache\"][\"w\" + str(l)]\n",
    "        b = parameters[\"b_cache\"][\"b\" + str(l)]\n",
    "        z = np.dot(w,activation) + b\n",
    "        activation = relu(z)\n",
    "        z_cache[\"z\" + str(l)] = z\n",
    "        a_cache[\"a\" + str(l)] = activation\n",
    "    \n",
    "    w = parameters[\"w_cache\"][\"w\" + str(l+1)]\n",
    "    b = parameters[\"b_cache\"][\"b\" + str(l+1)]\n",
    "    z = np.dot(w,activation) + b\n",
    "    y_hat = softmax(z)\n",
    "    z_cache[\"z\" + str(l+1)] = z\n",
    "    a_cache[\"a\" + str(l+1)] = y_hat\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y_hat):\n",
    "    cost = np.sum(y*np.log(abs(y_hat))) + np.sum((1-y)*np.log(abs(1-y_hat)))\n",
    "    cost = -(cost)/m\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myback(z_cache,w_cache,a_cache,y_hat,layers):\n",
    "    \n",
    "    l = len(layers)-1\n",
    "    w_l = w_cache[\"w\" + str(l)]\n",
    "    a_l = a_cache[\"a\" + str(l-1)]\n",
    "    \n",
    "    dz = y_hat - y\n",
    "    da = np.dot(w_l.T,dz)\n",
    "    dw_l = 1/m*(np.dot(dz,a_l.T))\n",
    "    db_l = 1/m*(np.sum(dz,axis=1,keepdims=True))\n",
    "    \n",
    "    dw_cache[\"dw\" + str(l)] = dw_l\n",
    "    db_cache[\"db\" + str(l)] = db_l\n",
    "    \n",
    "    for what in range(l-1,0,-1):\n",
    "        z_l = z_cache[\"z\" + str(what)]\n",
    "        w_l = w_cache[\"w\" + str(what)]\n",
    "        a_l = a_cache[\"a\" + str(what-1)]\n",
    "        \n",
    "        dz = da*backrelu(z_l)\n",
    "        dw_l = 1/m*(np.dot(dz,a_l.T))\n",
    "        db_l = 1/m*(np.sum(dz,axis=1,keepdims=True))\n",
    "        da_l = np.dot(w_l.T,dz)\n",
    "        \n",
    "        da = da_l\n",
    "        \n",
    "        dw_cache[\"dw\" + str(what)] = dw_l\n",
    "        db_cache[\"db\" + str(what)] = db_l\n",
    "\n",
    "        \n",
    "    return dw_cache,db_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(w_cache,b_cache,dw_cache,db_cache,layers):\n",
    "    \n",
    "    L = len(layers)\n",
    "    lum=1\n",
    "    while lum < L:\n",
    "        w_cache[\"w\" + str(lum)] = w_cache[\"w\" + str(lum)] - alpha*dw_cache[\"dw\" + str(lum)]\n",
    "        b_cache[\"b\" + str(lum)] = b_cache[\"b\" + str(lum)] - alpha*db_cache[\"db\" + str(lum)]\n",
    "        lum = lum + 1\n",
    "    \n",
    "    parametrics = {\"w_cache\" : w_cache,\n",
    "                  \"b_cache\" : b_cache}\n",
    "    \n",
    "    return parametrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,Y,layers,alpha,number_iters):\n",
    "    costs = []\n",
    "    parameters = layer_parameters()\n",
    "    for j in range(number_iters):\n",
    "        y_hat = linear_forward(parameters,X)\n",
    "        cost = cost_function(y_hat)\n",
    "        costs.append(cost)\n",
    "        dw_cache,db_cache = myback(z_cache,w_cache,a_cache,y_hat,layers)\n",
    "        parameters = update_parameters(w_cache,b_cache,dw_cache,db_cache,layers)\n",
    "        print(j,\"\\t\",cost)\n",
    "    return parameters,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f500e8946a0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHdFJREFUeJzt3WtwXHeZ5/Hv0ze17pJt2ZZvkTOxswTCJsFkEkIgDCwkHpbscJlN2JqEDIuLGVILu7NVy0AVw/KGYqcWZthskQ2VVAjLBHaAmQ0zyUKWIRtucbCNc3FMEsdOsGPHli1bknXr27MvzpHcarWklt1S63T/PlVdffr06e5Hp6Xf+es5p0+buyMiIvUlVusCRESk+hTuIiJ1SOEuIlKHFO4iInVI4S4iUocU7iIidUjhLiJShxTuIiJ1SOEuIlKHErV64VWrVnlfX1+tXl5EJJJ279590t175luuZuHe19fHrl27avXyIiKRZGavVLKc2jIiInVI4S4iUocU7iIidUjhLiJShxTuIiJ1SOEuIlKHFO4iInUocuH+4vFhvvCD55jI5WtdiojIshW5cD9yeoz7fn6IXxw4VetSRESWrciF+1suWUl7U4IfPXe81qWIiCxbkQv3pkScKzZ18dThM7UuRURk2YpcuAO8rreDAyfOUih4rUsREVmWIhnu67uayeQLnBrJ1LoUEZFlKbLhDvDqmbEaVyIisjxFMtxXtqUAGBiZqHElIiLLUyTDvbslCPczo9kaVyIisjxFMty7WpIAnFa4i4iUFclw70gniRmcGdUOVRGRciIZ7rGY0ZpKMDyeq3UpIiLLUiTDHaA5FWc8q/PLiIiUM2+4m1nazJ40s6fMbJ+Z/ecyyzSZ2XfM7ICZ7TSzvsUotlhLKs5oRuEuIlJOJSP3CeD33P2fA1cAN5rZNSXLfBQ47e6XAF8BvlTdMmdKJxXuIiKzmTfcPXA2vJkML6Wf+78Z+EY4/V3gnWZmVauyjJZUnLGseu4iIuVU1HM3s7iZ7QVOAI+6+86SRdYDhwHcPQcMAiurWWipllSCMY3cRUTKqijc3T3v7lcAG4CrzewNJYuUG6XPOKuXme0ws11mtqu/v3/h1RZpVs9dRGRWCzpaxt3PAI8BN5bcdQTYCGBmCaATGCjz+HvcfZu7b+vp6Tmvgic1J+OM6WgZEZGyKjlapsfMusLpZuBdwG9KFnsIuD2c/iDwT+6+qOfj1dEyIiKzS1SwTC/wDTOLE2wM/pe7/4OZfQHY5e4PAfcC3zSzAwQj9lsWreJQcyrOuMJdRKSsecPd3Z8Griwz/3NF0+PAh6pb2txaUnFG1ZYRESkrsp9QbUrEyRecXL5Q61JERJadyIZ7Mh6Uns3rq/ZEREpFNtxTiaD0TE4jdxGRUpEP94m8+u4iIqWiG+7x4HNTasuIiMwU3XBXW0ZEZFaRDfdzO1QV7iIipSIb7qm4Ru4iIrOJbrhP7lBVuIuIzBDdcFdbRkRkVtENd+1QFRGZVeTDXSN3EZGZIhvuSe1QFRGZVWTDfaoto5G7iMgM0Q13jdxFRGYV3XDXyF1EZFbRDXeN3EVEZhXZcE/qUEgRkVlFN9zDs0LmCjorpIhIqeiGe0zHuYuIzCay4R6LGfGYKdxFRMqIbLhD0JrRl3WIiMwU8XCPaeQuIlLGvOFuZhvN7Cdmtt/M9pnZJ8ssc4OZDZrZ3vDyucUpd7qUwl1EpKxEBcvkgD9z9z1m1g7sNrNH3f25kuV+6u7vrX6Js0vEjWxObRkRkVLzjtzd/Zi77wmnh4H9wPrFLqwSyXiMbEEjdxGRUgvquZtZH3AlsLPM3dea2VNm9oiZvb4Ktc0raMto5C4iUqqStgwAZtYGfA/4lLsPldy9B7jI3c+a2Xbg74EtZZ5jB7ADYNOmTedd9KSgLaORu4hIqYpG7maWJAj2b7n790vvd/chdz8bTj8MJM1sVZnl7nH3be6+raen5wJLD9oyObVlRERmqORoGQPuBfa7+5dnWWZtuBxmdnX4vKeqWWg5yXiMjNoyIiIzVNKWuQ74I+AZM9sbzvsMsAnA3e8GPgj8iZnlgDHgFndf9NRNqi0jIlLWvOHu7j8DbJ5l7gLuqlZRldKHmEREyov8J1TVlhERmSni4a62jIhIOREPdx0tIyJSTuTDXR9iEhGZKdLhnoibvmZPRKSMSId7Sm0ZEZGyIh3uasuIiJQX/XBXW0ZEZIaIh7vplL8iImVEPNzVlhERKSfy4Z4vOIWCAl5EpFikwz0RD055o9aMiMh0kQ73VDwoX60ZEZHpIh3uycmRu46YERGZJtLhnpgcuastIyIyTaTDXW0ZEZHyIh3uyYTaMiIi5UQ63BOxoHydX0ZEZLpIh3sybMtkcmrLiIgUi3S4pybbMvoeVRGRaSId7mrLiIiUF+lwV1tGRKS8SIe72jIiIuXNG+5mttHMfmJm+81sn5l9sswyZmZfNbMDZva0mV21OOVONzlyV1tGRGS6RAXL5IA/c/c9ZtYO7DazR939uaJlbgK2hJffBb4WXi+qyZ672jIiItPNO3J392PuviecHgb2A+tLFrsZeMADTwBdZtZb9WpLqC0jIlLegnruZtYHXAnsLLlrPXC46PYRZm4AMLMdZrbLzHb19/cvrNIyklOnH1C4i4gUqzjczawN+B7wKXcfKr27zENm9Erc/R533+bu23p6ehZWaRmTJw7L6dwyIiLTVBTuZpYkCPZvufv3yyxyBNhYdHsDcPTCy5vb5Cl/Mxq5i4hMU8nRMgbcC+x39y/PsthDwG3hUTPXAIPufqyKdZaVUltGRKSsSo6WuQ74I+AZM9sbzvsMsAnA3e8GHga2AweAUeCO6pc6k9oyIiLlzRvu7v4zyvfUi5dx4BPVKqpSasuIiJQX6U+oJmNqy4iIlBPpcI/FjHjM1JYRESkR6XCHoDWjkbuIyHR1EO4x9dxFREpEPtxT8ZjaMiIiJSIf7gm1ZUREZoh8uKstIyIyU+TDXW0ZEZGZIh/uasuIiMwU+XBPxmMKdxGREnUS7mrLiIgUq4NwV1tGRKRUHYS72jIiIqXqJNzVlhERKVYH4a62jIhIqciHeyoRYyKncBcRKRb5cE8n44xn87UuQ0RkWYl8uDcn44xnNXIXESkW+XDXyF1EZKbIh3tzMs5YNk/wNa4iIgL1EO6pOPmC63BIEZEikQ/3pkTwI4zn1JoREZk0b7ib2X1mdsLMnp3l/hvMbNDM9oaXz1W/zNk1p+IAjGcU7iIikxIVLHM/cBfwwBzL/NTd31uVihaoORmE+5h2qoqITJl35O7ujwMDS1DLeZkMdx0OKSJyTrV67tea2VNm9oiZvb5Kz1mRtEbuIiIzVNKWmc8e4CJ3P2tm24G/B7aUW9DMdgA7ADZt2lSFly4Kd/XcRUSmXPDI3d2H3P1sOP0wkDSzVbMse4+7b3P3bT09PRf60kDRDlWN3EVEplxwuJvZWjOzcPrq8DlPXejzViqdDA+FVLiLiEyZty1jZg8CNwCrzOwI8BdAEsDd7wY+CPyJmeWAMeAWX8KPi+poGRGRmeYNd3e/dZ777yI4VLImFO4iIjNF/hOqkz330QmFu4jIpMiHe2sq+Ofj7ESuxpWIiCwfkQ/3WMxoa0oo3EVEikQ+3IEg3McV7iIik+oj3NMauYuIFKuPcG9KMDSeBaB/eIIHfvlyTesREam1apx+oObai0bun/ibPTx5aIDrt/SweVVrjSsTEamNuhm5T/bcXxscB6Cgr90TkQZWF+FePHLPF4JQ1+kIRKSR1UW4tzUlp0buybgBMKqzRIpIA6uPcE8nOJvJUSg48VgQ7tm8vrxDRBpXXYR7RzqBOwxP5IgFJ6gkl1fPXUQaV12Ee3dLCoDTI5lz4V7QyF1EGlddhPuKtiDcB0YzhNlOViN3EWlg9RHu4ch94GwGU1tGRKROwr313Mg93J+qtoyINLT6CveinrvaMiLSyOoi3FtScZoSsXCHajAvp0MhRaSB1UW4mxkrWlOcGjnXc88WNHIXkcZVF+EOQWtGI3cRkUBdhfup4uPc1XMXkQZWN+G+uj3N8aHxqdtZHS0jIg2sbsJ9fVcQ7pO9do3cRaSRzRvuZnafmZ0ws2dnud/M7KtmdsDMnjazq6pf5vx6u5opOLw2OAao5y4ija2Skfv9wI1z3H8TsCW87AC+duFlLdy6rmYAjg9NADpaRkQa27zh7u6PAwNzLHIz8IAHngC6zKy3WgVWal1netrtbE4jdxFpXNXoua8HDhfdPhLOm8HMdpjZLjPb1d/fX4WXPqc3HLlPyqgtIyINrBrhbmXmle2JuPs97r7N3bf19PRU4aXPaWtK0NmcnLqtr9kTkUZWjXA/Amwsur0BOFqF512wS1a3TU1PqC0jIg2sGuH+EHBbeNTMNcCgux+rwvMu2CU958JdI3cRaWSJ+RYwsweBG4BVZnYE+AsgCeDudwMPA9uBA8AocMdiFTufzT2tU9MauYtII5s33N391nnud+ATVavoArzpou6paY3cRaSR1c0nVAHe3LeCnZ95J9dvWaWRu4g0tLoKd4A1HWmaEnHGswp3EWlcdRfuAOlkTG0ZEWlodRnu3S0pTo9mal2GiEjN1GW4r2xLcWY0S1afUhWRBlWn4d4EoNG7iDSsugz3yZOIHR4YrXElIiK1UZfh/s96OwB47thwjSsREamNugz3dZ1pulqSPHX4TK1LERGpiboMdzPj7Vt7+PH+49qpKiINqS7DHWD75b2cHs3yy5dO1boUEZElV7fh/vatPbSnEzz45G9rXYqIyJKr23BPJ+N85C19/J99r/Hice1YFZHGUrfhDnDHdZtpTsb56x+/WOtSRESWVF2H+4rWFB+7/mL+4eljPPb8iVqXIyKyZOo63AH+9B2/wyWr2/jM959hYESfWBWRxlD34d6UiPOVP7yCkyMZ/vRbu3W2SBFpCHUf7gCXb+jkSx+4nJ2HBrjtvicZGs/WuiQRkUXVEOEO8AdXbuCv/vUV7HnlNLfe8wQnhsZrXZKIyKJpmHAHuPmK9Xz99m281H+Wm/76p/z0xf5alyQisigaKtwB3nHpan5w51vpbk1x231P8sWH96sPLyJ1p+HCHWDLmnZ+cOdbueXNm/gfjx/kvf/tZ/zipZO1LktEpGoqCnczu9HMnjezA2b26TL3f8TM+s1sb3j5t9UvtbqaU3G++P7Luf+ONzOWyfPhr+/ko/f/ir06k6SI1AFz97kXMIsDLwD/AjgC/Aq41d2fK1rmI8A2d7+z0hfetm2b79q163xqrrrxbJ57f3aIex4/yOBYlqs3r+CPr+vjna9bQzLekP/ciMgyZWa73X3bfMslKniuq4ED7n4wfOJvAzcDz835qAhJJ+N84h2XcPtb+nhw52+5/xcv8/H/uYdVbSnef9UGPvSmDWxZ017rMkVEKlZJuK8HDhfdPgL8bpnlPmBmbyMY5f97dz9cZpllra0pwcfedjF3XNfHY8/387e7D3NfOKK/dE072y/v5fffuJZLVivoRWR5qyTcrcy80l7OD4AH3X3CzD4OfAP4vRlPZLYD2AGwadOmBZa6dBLxGO+6bA3vumwNJ89O8IOnjvLIM6/xVz9+ga/83xfYsrqNd79+DTdcuporN3aRUOtGRJaZSnru1wKfd/f3hLf/HMDdvzjL8nFgwN0753re5dRzr9TxoXF+uO81/vHpY+x65TT5gtORTnD91h5u2NrD2y/tYXV7utZlikgdq2bP/VfAFjPbDLwK3AJ8uOTFet39WHjzfcD+BdYbCWs60tx2bR+3XdvH4FiWnx84yWPPn+Cx5/v5x6eDH3/rmjauuXgl11y8kqs3r2BVW1ONqxaRRjRvuLt7zszuBH4IxIH73H2fmX0B2OXuDwH/zszeB+SAAeAji1jzstDZnGT75b1sv7wXd+e5Y0M8/sJJnjh4iu/uPsIDv3wFOBf2b+5bwVUXdbOuM41ZuU6XiEj1zNuWWSxRbMtUKpsv8OyrgzxxcIAnDp7iVy8PMJoJPgW7ur2JqzZ1c+WmLq66qJvL13eSTsZrXLGIREWlbRmF+xLI5gv85tgwvz58mj2vnObXh8/wyqlRABIx47J1HbxxQydvWNfJ69d1snVtG00JBb6IzKRwX+ZOnp1g72/PsOe3p9nz29Pse3WI4YkcEAT+ljXtvGFdB69f18Eb1nfyut4OWpsq2UUiIvVM4R4xhYJz+PQoz746xL6jgzx7dIh9rw5yKvz2KDPY2N3C1jXtbF3TxqVr29myup2Le1rV1hFpINU8WkaWQCxmXLSylYtWtvL7b+wFwN05PjTBs68Osu/oEC8cH+aF48M89vwJcoVgoxwz6FvVytbV7WxdGwT/xava6FvVQktKb69Io9Jf/zJmZqztTLO2M827LlszNT+TK3Do5AgvHB/mxePDPB+G/o+ee41C0T9iazvSbF7VyuaeVjavbJ2a3tjdQiqhD16J1DOFewSlEjEuXdvOpWunnwZhPJvnYP8Ih06OcOjkWQ6dHOXQybM88swxTo+e+2rBeMzY0N3MRStb2djdzMYVLWzobmZjdwsbV7TQ3ZLU4ZoiEadwryPpZJzL1nVw2bqOGfedGc2EoT/CyydHOHhyhFdOjfLMkTPTgh+gNRVnQ3cLG1c0s6E7DP4VLWzsbmF9VzMdzQmFv8gyp3BvEF0tKa7clOLKTd0z7hsez3Lk9BiHB0aD69OjHB4Y48jpUZ44OMDZ8CieSc3JOL1daXo706ztaGZdV9A6WtfZPHWtDYBIbSnchfZ0ktf1Jnld78wRv7tzZjQ7FfjHBsc4NjjOa4PjHB0c4xcvneT40Pi0Xj9M3wCs6Uizuj1NT3sTq9ubpl23NWkjILIYFO4yJzOjuzVFd2uKN27oKrtMLl+g/+wExwbHOXZmfMYGYOfBAfqHJ8jkCzMe25yMlw39yY1BT3sTK1pTrGhN6ZBPkQVQuMsFS8Rj9HY209vZDLOcydndGRzLcmJ4ghNDE/SfHQ+uhyc4MRxcv3B8mJ8fOMnQeK7sc7Sm4qxoS7GitYmVYeBPXq9oTbGy6L6VbSkdCioNTb/9siTMjK6WFF0tKbbO861W49n8tNAfGMkwMDLBqZFMOJ3htcFxnjs6xMBIpux/BADpZIyVrU10tybpak7R2ZKkqzlJV8u5253Nk/NSdIW39R+C1AOFuyw76WQ8ODpnRcu8y7o7ZydyDIxkgvA/mzk3HW4QzoxmOTOa4ejgGIOjWc6MZcmX7iSY9voxuprPhX3xxqC9KUFHc5L2dIL29OR1go50ko50krZ0gnhM+xCk9hTuEmlmFoZskotWtlb0mMkNwpnRLINj2SD8xzJFt8MNwliWwdEsh06OcGb0DGfGsmRy5f9LKNaaitOeTtLRXLwBKN0QnJvX1pSgdeoSp60pQXMyrh3NckEU7tJwijcIGxf42IlcnuHxXHjJMjyeY2gsvA5vn5sObp86m+HlkyNT87P5+c/nZAatqSDsg+vS6QStqTitTcHGoSXcKLSmiqbD282pOM3JuD6V3GAU7iIL0JSI09QWP+9v2HJ3JnKFaRuCkYkcZyeC65FMPrieyDEyEU5nzt1+bWg8XD7PaCY39T0BlUjEjOZkPAj7MPAnr1tScdLhdTA/cW5+Kk5L6eNKH5OKk07EiakltWwo3EWWkJmRTgahuHru/coVyRecsWx+agMxOpEv2lAEG4SxbJ7xbLAxGMsUGMvmGMvkGc0E941l8gyOZaemx7LBfZW0oEol40Y6EacpGacpESOdjNGUiM99nYyTTsSmHlN8e8Z10eOC1wluaz/HTAp3kQiLx4y2sDWzZv7FF2RywzGWKQ79XNHGYvrGYCJbYDxX/noivD41kpmaP57NM5ErTF1fyNnH4zEjFY+RSoSXeIymxLnbyXhs+v2JGE0lyxffN3V7lmWaEjFS8fi0xyTjRlPRvFpvcBTuIlJW8YZjsbk7mXzhXNiHG4Txua6zecZzBSayBTL54D+NTK4w9TzFtyenRzO54L58+ftzcxxFtVAxY9qGJRmPkUwYyXiMW9+8iY+97eKqvVY5CncRqTkzC/ZnJOJ0pJM1q6NQ8Okbh3yBbNEGYKLMBqF4wzIx9Rgnmy+QzYe3i+Zl8gV62s9vn81CKNxFREKxmJGOxevig2w6NkpEpA4p3EVE6lBF4W5mN5rZ82Z2wMw+Xeb+JjP7Tnj/TjPrq3ahIiJSuXnD3cziwH8HbgIuA241s8tKFvsocNrdLwG+Anyp2oWKiEjlKhm5Xw0ccPeD7p4Bvg3cXLLMzcA3wunvAu80nRhDRKRmKgn39cDhottHwnlll3H3HDAIrCx9IjPbYWa7zGxXf3//+VUsIiLzqiTcy43AS4/0r2QZ3P0ed9/m7tt6enoqqU9ERM5DJeF+BKadPG8DcHS2ZcwsAXQCA9UoUEREFq6SDzH9CthiZpuBV4FbgA+XLPMQcDvwS+CDwD+5z32miN27d580s1cWXjIAq4CT5/nYxbRc64LlW5vqWhjVtTD1WNdFlSw0b7i7e87M7gR+CMSB+9x9n5l9Adjl7g8B9wLfNLMDBCP2Wyp43vPuy5jZLnffdr6PXyzLtS5YvrWproVRXQvTyHVVdPoBd38YeLhk3ueKpseBD1W3NBEROV/6hKqISB2KarjfU+sCZrFc64LlW5vqWhjVtTANW5fNs99TREQiKKojdxERmUPkwn2+k5gt8mtvNLOfmNl+M9tnZp8M53/ezF41s73hZXvRY/48rPV5M3vPItb2spk9E77+rnDeCjN71MxeDK+7w/lmZl8N63razK5apJouLVone81syMw+VYv1ZWb3mdkJM3u2aN6C14+Z3R4u/6KZ3b5Idf2lmf0mfO2/M7OucH6fmY0Vrbe7ix7zpvD9PxDWfkGn/5ilrgW/b9X+e52lru8U1fSyme0N5y/l+potG2r3O+bukbkQHIr5EnAxkAKeAi5bwtfvBa4Kp9uBFwhOpvZ54D+WWf6ysMYmYHNYe3yRansZWFUy778Anw6nPw18KZzeDjxC8Mnia4CdS/TevUZwjO6Sry/gbcBVwLPnu36AFcDB8Lo7nO5ehLreDSTC6S8V1dVXvFzJ8zwJXBvW/Ahw0yLUtaD3bTH+XsvVVXL/fwU+V4P1NVs21Ox3LGoj90pOYrZo3P2Yu+8Jp4eB/cw8z06xm4Fvu/uEux8CDhD8DEul+IRu3wD+VdH8BzzwBNBlZr2LXMs7gZfcfa4Pri3a+nL3x5n5qemFrp/3AI+6+4C7nwYeBW6sdl3u/iMPztEE8ATBp8JnFdbW4e6/9CAhHij6WapW1xxme9+q/vc6V13h6PsPgQfneo5FWl+zZUPNfseiFu6VnMRsSVhwzvorgZ3hrDvDf6/um/zXi6Wt14EfmdluM9sRzlvj7scg+OUDVtegrkm3MP2PrtbrCxa+fmqx3v6YYIQ3abOZ/drM/p+ZXR/OWx/WshR1LeR9W+r1dT1w3N1fLJq35OurJBtq9jsWtXCv6ARli16EWRvwPeBT7j4EfA34HeAK4BjBv4awtPVe5+5XEZx3/xNm9rY5ll3S9WhmKeB9wN+Gs5bD+prLbHUs9Xr7LJADvhXOOgZscvcrgf8A/I2ZdSxhXQt935b6/byV6QOIJV9fZbJh1kVnqaFqtUUt3Cs5idmiMrMkwZv3LXf/PoC7H3f3vLsXgK9zrpWwZPW6+9Hw+gTwd2ENxyfbLeH1iaWuK3QTsMfdj4c11nx9hRa6fpasvnBH2nuBfxO2DgjbHqfC6d0E/eytYV3FrZtFqes83relXF8J4P3Ad4rqXdL1VS4bqOHvWNTCfeokZuFo8BaCk5YtibCndy+w392/XDS/uF/9B8DknvyHgFss+BrCzcAWgh051a6r1czaJ6cJdsg9y7kTuhFe/++ium4L99hfAwxO/uu4SKaNqGq9voosdP38EHi3mXWHLYl3h/OqysxuBP4T8D53Hy2a32PBN6NhZhcTrJ+DYW3DZnZN+Dt6W9HPUs26Fvq+LeXf67uA37j7VLtlKdfXbNlALX/HLmQPcS0uBHuZXyDYCn92iV/7rQT/Ij0N7A0v24FvAs+E8x8Ceose89mw1ue5wD3yc9R1McGRCE8B+ybXC8EXpvwYeDG8XhHON4KvTnwprHvbIq6zFuAU0Fk0b8nXF8HG5RiQJRgdffR81g9BD/xAeLljkeo6QNB3nfwduztc9gPh+/sUsAf4l0XPs40gbF8C7iL8gGKV61rw+1btv9dydYXz7wc+XrLsUq6v2bKhZr9j+oSqiEgdilpbRkREKqBwFxGpQwp3EZE6pHAXEalDCncRkTqkcBcRqUMKdxGROqRwFxGpQ/8fQ8UCek08HTYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.47 %\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "df = pd.read_csv('mnist_test.csv',header = None)\n",
    "data = np.array(df)\n",
    "X_test = (data[:,1:].transpose())/255\n",
    "Y_test = data[:,0:1].transpose()\n",
    "accuracy = 0\n",
    "m_test = X_test.shape[1]\n",
    "predict = np.zeros((1,m_test))\n",
    "A_test = linear_forward(parameters,X_test)\n",
    "for i in range(m_test):\n",
    "    max = 0\n",
    "    for j in range(10):\n",
    "        if A_test[j,i] > max:\n",
    "            max = A_test[j,i]\n",
    "            max_index = j\n",
    "        predict[0,i] = max_index\n",
    "    if predict[0,i] == Y_test[0,i]:\n",
    "        accuracy = accuracy + 1\n",
    "accuracy = (accuracy/m_test)*100\n",
    "print(accuracy,\"%\")\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "x_1=[]\n",
    "y_1=[]\n",
    "with open('data.csv','rt')  as f:\n",
    "    data = csv.reader(f)\n",
    "    for row in data:\n",
    "        x_1.append(row[:2])\n",
    "        y_1.append(row[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x_1[0:],dtype=np.float).T\n",
    "y=np.array(y_1[0:],dtype=np.float).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = [2,5,5,1]\n",
    "w_cache = dict()\n",
    "b_cache = dict()\n",
    "z_cache = dict()\n",
    "a_cache = dict()\n",
    "m=118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_parameters(): \n",
    "    num_layers = 4\n",
    "    for z in range(1,num_layers):\n",
    "        w = np.random.randn(layer[z],layer[z-1])*0.01\n",
    "        b = np.zeros((layer[z],1))\n",
    "        w_cache[\"w\" + str(z)]=w\n",
    "        b_cache[\"b\" + str(z)]=b\n",
    "        print('w',w.shape)\n",
    "        print('b', b.shape)\n",
    "    \n",
    "    parameters = {\"w_cache\" : w_cache,\n",
    "                  \"b_cache\" : b_cache}\n",
    "    #print('i got parameters')\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(parameters,activation,i):\n",
    "    w = parameters[\"w_cache\"][\"w\" + str(i)]\n",
    "    b = parameters[\"b_cache\"][\"b\" + str(i)]\n",
    "    \n",
    "    z = np.dot(w,activation) + b\n",
    "    #print('w shape', w.shape)\n",
    "    #print('a shape', activation.shape)\n",
    "    #print('z shape', z.shape)\n",
    "    activation = np.tanh(z)\n",
    "    z_cache[\"z\" + str(i)]=z\n",
    "    a_cache[\"a\" + str(i+1)]=activation\n",
    "    #print('activation shape', activation.shape)\n",
    "    i+=1\n",
    "    #print('i got linear forward')\n",
    "    if i == len(layer):\n",
    "        return activation\n",
    "    else:\n",
    "        return linear_forward(parameters,activation,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y_hat):\n",
    "    print('chal hatt',y_hat.shape)\n",
    "    cost = np.dot(y,np.log(abs(y_hat)).T) + np.dot((1-y),np.log(abs(1-y_hat)).T)\n",
    "    cost = -cost/118\n",
    "    #print(\"i got cost which is\",cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(w_cache,z_cache,a_cache,da,layer_number):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for what in range(0,4):\n",
    "        z_l = z_cache[\"z\" + str(layer_number)]\n",
    "        w_l = w_cache[\"w\" + str(layer_number)]\n",
    "        a_l = a_cache[\"a\" + str(layer_number)]\n",
    "    \n",
    "        print('z_l shape', z_l.shape)\n",
    "        print('a_l shape', a_l.shape)\n",
    "        print('w_l shape', w_l.shape)\n",
    "    \n",
    "        dz = np.multiply(da,1-np.power(z_l,2))\n",
    "        print('dz shape', dz.shape)\n",
    "    to\n",
    "        dw_l = 1/m*(np.dot(dz,a_l.T))\n",
    "        print('dw_l shaep', dw_l.shape)\n",
    "    \n",
    "        db_l = 1/m*(np.sum(dz,axis=1,keepdims=True))\n",
    "        da_l = np.dot(w_l.T,dz)\n",
    "        print('da shape', da_l.shape)\n",
    "        w_cache = update_parameters(dw_l,db_l,layer_number,w_cache,b_cache,alpha=0.7)\n",
    "        layer_number+=1\n",
    "        da = da_l\n",
    "    #print('i got backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(dw_l,db_l,layer_number,w_cache,b_cache,alpha = 0.7):\n",
    "    w_cache[\"w\" + str(layer_number)] = w_cache[\"w\" + str(layer_number)] - alpha*dw_l\n",
    "    b_cache[\"b\" + str(layer_number)] = b_cache[\"b\" + str(layer_number)] - alpha*db_l\n",
    "    \n",
    "    print('WHAT THE FUCCC')\n",
    "    \n",
    "    return w_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(x,y,l):\n",
    "    \n",
    "    parameters = layer_parameters()\n",
    "    \n",
    "    a_cache[\"a\" + str(l)] = x\n",
    "    activation = x\n",
    "    \n",
    "    y_hat = linear_forward(parameters,activation,l)\n",
    "    cost = cost_function(y_hat)\n",
    "    \n",
    "    da = - (y/y_hat) - ((1-y)/(1-y_hat))\n",
    "    \n",
    "    backward_propagation(w_cache,z_cache,a_cache,da,layer_number)\n",
    "    \n",
    "    #print('i did it boi')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w (5, 2)\n",
      "b (5, 1)\n",
      "w (5, 5)\n",
      "b (5, 1)\n",
      "w (1, 5)\n",
      "b (1, 1)\n",
      "chal hatt (1, 118)\n",
      "z_l shape (5, 118)\n",
      "a_l shape (2, 118)\n",
      "w_l shape (5, 2)\n",
      "dz shape (5, 118)\n",
      "dw_l shaep (5, 2)\n",
      "da shape (2, 118)\n",
      "WHAT THE FUCCC\n",
      "z_l shape (5, 118)\n",
      "a_l shape (5, 118)\n",
      "w_l shape (5, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,118) (5,118) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5b5b23793a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-8319b8389cb5>\u001b[0m in \u001b[0;36mnn_model\u001b[0;34m(x, y, l)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print('i did it boi')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-fb716469cafd>\u001b[0m in \u001b[0;36mbackward_propagation\u001b[0;34m(w_cache, z_cache, a_cache, da, layer_number)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w_l shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dz shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,118) (5,118) "
     ]
    }
   ],
   "source": [
    "layer_number=1\n",
    "i=1\n",
    "a_cache['a' + str(i)] = x\n",
    "u = nn_model(x,y,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1,2,3,4,5,6,98,87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 98\n",
      "7 87\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(a):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
